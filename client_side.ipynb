{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import pylab\n",
    "import matplotlib.mlab as ml\n",
    "from scipy.fftpack import fft\n",
    "import pyaudio\n",
    "import struct\n",
    "import pickle\n",
    "\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hashtable.pkl\", \"rb\") as input_file:\n",
    "    hashtable = pickle.load( input_file)\n",
    "with open(\"songid.pkl\", \"rb\") as input_file:\n",
    "    song_dict = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_FS = 44100\n",
    "DEFAULT_WINDOW_SIZE = 4096\n",
    "DEFAULT_OVERLAP_RATIO = 0.5\n",
    "DEFAULT_FAN_VALUE = 15\n",
    "DEFAULT_AMP_MIN = 10\n",
    "\n",
    "def graph_spectrogram(sound_info, frame_rate):\n",
    "    pylab.figure(num=None, figsize=(19, 12))\n",
    "    pylab.subplot(111)\n",
    "    pylab.specgram(sound_info, Fs=frame_rate)\n",
    "    pylab.savefig('spectrogram.png')\n",
    "\n",
    "\"\"\"\n",
    "Function that converts a byte string into a numpy array\n",
    "\"\"\"\n",
    "def _wav2array(nchannels, sampwidth, data):\n",
    "    num_samples, remainder = divmod(len(data), sampwidth * nchannels)\n",
    "    if remainder > 0:\n",
    "        raise ValueError('The length of data is not a multiple of '\n",
    "                         'sampwidth * num_channels.')\n",
    "    if sampwidth > 4:\n",
    "        raise ValueError(\"sampwidth must not be greater than 4.\")\n",
    "\n",
    "    if sampwidth == 3:\n",
    "        a = np.empty((num_samples, nchannels, 4), dtype=np.uint8)\n",
    "        raw_bytes = np.fromstring(data, dtype=np.uint8)\n",
    "        a[:, :, :sampwidth] = raw_bytes.reshape(-1, nchannels, sampwidth)\n",
    "        a[:, :, sampwidth:] = (a[:, :, sampwidth - 1:sampwidth] >> 7) * 255\n",
    "        result = a.view('<i4').reshape(a.shape[:-1])\n",
    "    else:\n",
    "        dt_char = 'u' if sampwidth == 1 else 'i'\n",
    "        a = np.fromstring(data, dtype='<%s%d' % (dt_char, sampwidth))\n",
    "        result = a.reshape(-1, nchannels)\n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "Function to convert stereo to mono\n",
    "\"\"\"\n",
    "\n",
    "def stereo2mono(audiodata, nchannels):\n",
    "#     if nchannels==1:\n",
    "#         return audiodata.astype(int)\n",
    "    audiodata = audiodata.astype(float)\n",
    "    d = audiodata.sum(axis=1) / 2\n",
    "    return d.astype(int)\n",
    "\n",
    "\"\"\"\n",
    "Class containing details of the wav file that has been read.\n",
    "Sample use:\n",
    "    song_x = song(\"abc.wav\")\n",
    "\"\"\"\n",
    "class song:\n",
    "    def __init__(self, file, songid):\n",
    "        wav = wave.open(file)\n",
    "        self.song_id = songid\n",
    "        self.title = file.split(\"/\")[-1]\n",
    "        self.rate = wav.getframerate()\n",
    "        self.nchannels = wav.getnchannels()\n",
    "        self.sampwidth = wav.getsampwidth()\n",
    "        self.nframes = wav.getnframes()\n",
    "        self.data = wav.readframes(self.nframes)\n",
    "        self.array = stereo2mono(_wav2array(self.nchannels, self.sampwidth, self.data), self.nchannels)\n",
    "        wav.close()\n",
    "    def spectrogram(self):\n",
    "        self.specgram, self.frequencies, self.times = ml.specgram(self.array, Fs=self.rate, NFFT = 4096, window = ml.window_hanning, noverlap = int(4096 * 0.5), mode='magnitude')\n",
    "        self.specgram = 10*np.log10(self.specgram)\n",
    "        self.specgram[self.specgram==-np.inf] = 0\n",
    "#         self.specgram = (1/20)*(np.exp(self.specgram))\n",
    "#         self.specgram[self.specgram<100000000000000000] = 100000000000000000\n",
    "#         self.specgram[self.specgram>10000000000000000000] = 10000000000000000000\n",
    "#         fig, ax = plt.subplots()\n",
    "#         ax.imshow(self.specgram, aspect='auto')\n",
    "#         ax.set_xlabel('Time')\n",
    "#         ax.set_ylabel('Frequency')\n",
    "#         ax.set_title(\"Spectrogram of \"+self.title)\n",
    "#         plt.gca().invert_yaxis()\n",
    "#         plt.show()\n",
    "    def find_key(self):\n",
    "        self.spectrogram()\n",
    "        all_times = self.specgram.transpose()\n",
    "        #self.all_times = all_times\n",
    "        bands = []\n",
    "        count = 0\n",
    "        for a in all_times:\n",
    "            l = []\n",
    "            x = max(a[0:10])\n",
    "            l.append((x, [list(a[0:10]).index(x),self.times[count]]))\n",
    "            x = max(a[10:20])\n",
    "            l.append((x, [list(a[10:20]).index(x)+10,self.times[count]]))\n",
    "            x = max(a[20:40])\n",
    "            l.append((x, [list(a[20:40]).index(x)+20,self.times[count]]))\n",
    "            x = max(a[40:80])\n",
    "            l.append((x, [list(a[40:80]).index(x)+40,self.times[count]]))\n",
    "            x = max(a[80:160])\n",
    "            l.append((x, [list(a[80:160]).index(x)+80,self.times[count]]))\n",
    "            x = max(a[160:510])\n",
    "            l.append((x, [list(a[160:510]).index(x)+160,self.times[count]]))\n",
    "            bands.append(l)\n",
    "            count+=1\n",
    "        l = []\n",
    "        #print('length',len(bands))\n",
    "        for a in bands:\n",
    "            for b in a:\n",
    "                l.append(b[0])\n",
    "        #l has all the amplitudes in bands\n",
    "        mean = .1*np.mean(l)\n",
    "        new_bands = []\n",
    "        for i in range(0, len(bands)):\n",
    "            a = bands[i]\n",
    "            m = [t[1] for t in a if t[0]>mean]\n",
    "            if len(m)!=0:\n",
    "                new_bands.append(m)\n",
    "        self.bands = new_bands\n",
    "    def cal_address(self):\n",
    "        new_bands = []\n",
    "        for ele in self.bands:\n",
    "            for sub in ele:\n",
    "                new_bands.append(sub)\n",
    "        self.addresses = {}\n",
    "        for i in range(3,len(new_bands)-4):\n",
    "            anchor_point = new_bands[i-3]\n",
    "            for ele in new_bands[i:i+5]:\n",
    "                diff = float(\"%.2f\"%(ele[1] - anchor_point[1]))\n",
    "                val =  float(\"%.2f\"%(anchor_point[1]))\n",
    "                if (anchor_point[0],ele[0],diff) not in self.addresses.keys():\n",
    "                    self.addresses[anchor_point[0],ele[0],diff] = []\n",
    "                self.addresses[anchor_point[0],ele[0],diff].append([val,self.song_id])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording\n",
      "done recording\n"
     ]
    }
   ],
   "source": [
    "#defining parameters\n",
    "\n",
    "chunk = 4096\n",
    "format = pyaudio.paInt16\n",
    "channels = 1\n",
    "rate = 44100\n",
    "record_seconds = 20\n",
    "wave_output_file = \"output.wav\"\n",
    "\n",
    "#define an audio object and input stream\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=format,channels=channels,rate=rate,input=True,frames_per_buffer=chunk)\n",
    "\n",
    "print(\"Recording\")\n",
    "\n",
    "frames = []\n",
    "for i in range(0,int((rate/chunk)*record_seconds)):\n",
    "    data = stream.read(chunk)\n",
    "    frames.append(data)\n",
    "print(\"done recording\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "wf = wave.open(wave_output_file,'wb')\n",
    "wf.setnchannels(channels)\n",
    "wf.setsampwidth(p.get_sample_size(format))\n",
    "wf.setframerate(rate)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kavya/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    }
   ],
   "source": [
    "total = song(\"output.wav\", 0)\n",
    "total.find_key()\n",
    "total.cal_address()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
